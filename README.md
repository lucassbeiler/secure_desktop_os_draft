## Draft proposing a secure and modern Linux-based OS.
Currently, security on the average desktop is poor: Much because proper sandboxing is rarely implemented and authenticity guarantees are restricted to the boot chain (if at all). This article describes a Linux-based operating system model that addresses these two core issues.

The operating system is based on Gentoo Hardened with the [musl](https://musl.libc.org/about.html) libc, [hardened_malloc](https://github.com/GrapheneOS/hardened_malloc#security-properties), the LLVM toolchain, and deployed using immutable kernel and rootfs images compiled in the cloud and A/B applied by the local updater, weekly. The OS is immutable and stateless. The operating system very well draws the line between what is the stateless, atomically updatable, immutable base OS image and what is user data with its own application layer, to the point where the operating system can simply be factory reset by wiping the user data partition, starting over on top of the same immutable, updated base OS that is always there, clean and cryptographically authentic from the firmware to the boot chain to the root file system, leveraging TPM 2.0, UEFI Secure Boot and [dm-verity](https://docs.kernel.org/admin-guide/device-mapper/verity.html). Being immutable, stateless, and having a strong trust chain also means that the underlying OS is extremely hardened against both malicious and non-malicious data corruption. It is basically unbreakable and extremely difficult to tamper with. 

To install an application not included in the base OS image, the OS leverages Flatpak (for now, a better alternative is needed as soon as possible as described below in this document) and security-restricted [Podman](https://github.com/containers/podman#overview-and-scope) containers (with [gVisor](https://gvisor.dev/docs/), seccomp, SELinux, Linux namespaces and dropped Linux capabilities) so that users can manage packages and temporary environments in an unprivileged, contained manner. The project will start from a minimal base, based on Gentoo Hardened with [musl](https://musl.libc.org/about.html), [runit](https://docs.voidlinux.org/config/services/index.html#services-and-daemons---runit) and a minimal, hardened kernel. It may seem like an inconvenient and restrictive OS, but it will be developed over time to be more seamless and convenient, without losing the fundamental security features that will be detailed below. The unprivileged container engine leveraged to manage containerized packages and environments is also hardened to act much more like a sandbox instead of just the thin layer of isolation and restrictions that containers usually provide. 

This OS is different from most Linux-based systems because, although it is immutable and stateless like some others, things like Full Verified Boot and this level of general system hardening are lacking even in immutable OSes like Fedora Silverblue, VanillaOS and openSUSE MicroOS and are only seen on OSes like [Android](https://source.android.com/docs/security/features/verifiedboot) and [ChromeOS](https://www.chromium.org/chromium-os/chromiumos-design-docs/verified-boot/).

### Index
 1. [Full Verified Boot & Trust Chain](#full-verified-boot--trust-chain)
 2. [User data and package management](#user-data-and-package-management)
 3. [Updating the OS](#updating-the-os)
 4. [Network security](#network-security)
 5. [Exploit mitigations enforced by toolchain](#exploit-mitigations-enforced-by-toolchain)
 6. [Display and audio servers](#display-and-audio-servers)
 7. [Mandatory Access Control](#mandatory-access-control)
 8. [Chosen C library and malloc implementations](#chosen-c-library-and-malloc-implementations)
 9. [Kernel hardening](#kernel-hardening)

### Full Verified Boot & Trust Chain
During boot, the trust chain is substantially enforced by the TPM 2.0 chip, UEFI's Secure Boot and Linux's [dm-verity](https://docs.kernel.org/admin-guide/device-mapper/verity.html). In summary:

1. The first three and the fifth reserved TPM 2.0 [PCR measurements](https://wiki.archlinux.org/title/Trusted_Platform_Module#Accessing_PCR_registers) will cryptographically attest that certain hardware components, as well as firmware and configuration, are in a "known good state", which also unfortunately means that it will not be meaningful if the hardware and/or firmware have already been tampered with before installing this OS. 
2. TPM 2.0 PCR7 will ensure that Secure Boot is enabled and that its configuration and enrolled certificates are in an untampered "known good state". 
3. Secure Boot then ensures that the bootloader, kernel and initrd are authentic. 
4. With its authenticity guaranteed by Secure Boot, the kernel will be able to reliably attest at the block level, using [dm-verity](https://docs.kernel.org/admin-guide/device-mapper/verity.html), that the immutable, image-deployed rootfs partition is authentic too before reading any data from its squashfs file system. 

If this entire chain of trust is satisfied, the operating system will boot and the user will be able to use it. Otherwise, depending on when the corruption happens, the TPM 2.0 chip will either refuse to unseal any secrets needed to decrypt the home partition or, if [dm-verity](https://docs.kernel.org/admin-guide/device-mapper/verity.html) fails, the kernel itself will collapse into a kernel panic and the system will not boot.

Speaking of encryption and confidentiality, the home partition needs to be encrypted, while the OS' rootfs doesn't, because the rootfs has no sensitive data and the /var directory is a volatile tmpfs (statelessness). The rootfs is immutable with its authenticity guaranteed by [dm-verity](https://docs.kernel.org/admin-guide/device-mapper/verity.html). Since all user data and apps are in the home partition, it is encrypted with LUKS2 and the key is only unsealed by the TPM 2.0 chip if the [PCR measurements](https://wiki.archlinux.org/title/Trusted_Platform_Module#Accessing_PCR_registers) mentioned in the first paragraph are satisfied, ensuring that authentic code is running. Otherwise, the home partition keeps itself at rest and encrypted. In the end, LUKS2+TPM2 and fscrypt work together, on different layers, because each user's home directory is individually encrypted with their own password, using Google's open source fscrypt for file-based encryption (FBE) of the entire home directory of a given user.

Finally, before trusting this OS model, choose your hardware manufacturers carefully. It is very important that the user's device and TPM 2.0 chip vendors have secure firmware implementations that are continuously updated and are under active support. The security of TPM 2.0, UEFI and Secure Boot implementations is of utmost importance as they are essential parts (and enforcers) of the trust chain.

### User data and package management
For context, "user packages" are the packages that the user wants to install and are NOT included in the base OS image. To enable this:
* The OS needs to allow managing user packages and environments in a way that doesn't require root privileges;
* The OS needs to allow managing user packages and environments in a way that enforces sandboxing with proper isolation and restrictions for these programs;
* The OS needs to allow managing user packages and environments in a way that ALWAYS guarantees the authenticity of the binaries, for their entire on-disk lifecycle, not only when installing/updating;

Since the main ways to manage user packages here are using containers and Flatpak, system root access is not so necessary as [Podman](https://github.com/containers/podman#overview-and-scope) and Flatpak both work without requiring root privileges from the user. So, as a big security step, system root access is completely prohibited, as it is mostly useless in this OS. Also, **the OS would implement all mitigations and restrictions to prevent a container from affecting the host via container escapes and other vectors, knowing that containers are not sandboxes nor virtual machines and are therefore much more prone to affect the host if not strictly constrainted not to do so**. Managing packages and temporary environments via containers and sandboxes is also great to keep user main environment clean and organized at all times and to keep these temporary environments also clean and reproducible.

Initially, Flatpak is used but currently has two issues:
* The isolation and the restrictions provided by Flatpak are more like the thin layer of isolation and restrictions that containers usually provide than a real sandbox mechanism. The syscall filtering is also weak. If we looked at Flatpak's isolation technologies as a sandbox, it would be far from ideal, especially when compared to Android, ChromeOS, iOS, Fuchsia and even macOS with the App Store and Windows 11 with Microsoft Store's UWP apps;
* Flatpak does not use [fs-verity](https://www.kernel.org/doc/html/v5.18/filesystems/fsverity.html) ([fs-verity](https://www.kernel.org/doc/html/v5.18/filesystems/fsverity.html) isn't [dm-verity](https://docs.kernel.org/admin-guide/device-mapper/verity.html), it ensures the authenticity of specific read-only files, not block devices) to ensure the authenticity of binaries in their on-disk lifecycle once installed. Flatpak only verifies signatures when installing/updating applications;

Despite these problems, Flatpak still provides some isolation and restrictions, so it is already better than traditional Linux package management. It is used here because it is, along with containers, a possible way to manage applications at the user level and without root privileges.

[Podman](https://github.com/containers/podman#overview-and-scope) runs the containers because it is capable of running with no root privileges and daemonlessly, as well as being compatible with Docker and the OCI standard. **Every container uses the open source Google's [gVisor](https://gvisor.dev/docs/), which is a Go reimplementation of most of the Linux kernel syscalls, bringing better security as containerized programs will not communicate directly with the OS kernel, but with a less privileged and memory safe intermediary running the Go reimplementation of its syscalls.** Along with [gVisor](https://gvisor.dev/docs/) restricting communication with the kernel, in the future, these containers will be treated much more like sandboxes, with strong seccomp filtering imposed and much of the Linux capabilities dropped, as well as SELinux policies further restricting the containers.

In the future, in order to be the primary way to install user applications, a containerization solution for distributing packages in a contained, unprivileged manner could be developed, with the same principles of security, isolation and restrictions mentioned in the paragraphs above, but distributing packages in very small rootfs images containing everything necessary. 
OK, it may seem very similar to the containers we already know, but:
1. These user package images would have authenticity always guaranteed via fs-verity. Once fs-verity is enabled for a given image file (which should happen right after the image is downloaded), it cannot be disabled and the file becomes immutable and cryptographically authenticated.
2. Secret private keys were used to sign user package images on the build server. The respective certificates are in the kernel keyring that runs locally on the users' devices. Finally, [the Linux Integrity Policy Enforcement LSM (IPE)](https://lwn.net/Articles/921767/) is used to enforce that the container-based package manager can only run image files with a valid fs-verity signature. This is the final link in the trust chain. **But what about images built by the user? Perhaps this strategy is only feasible to install applications and Podman should still be supported for the user to run and build images for temporary containerized environments due to its flexibility.**

The home partition is the only persistent RW location on the entire OS, and uses BTRFS, it does not necessarily have security reasons, but is due to the robustness of BTRFS and its native checksumming for integrity guarantees, which plays nicely against **non-malicious** user data corruption (e.g. power outages). Another alternative to ensure RW user data integrity against non-malicious corruption would be to either use ZFS (disregarded because it is not part of the upstream kernel) or dm-integrity over ext4, f2fs, etc, but dm-integrity introduces greater overhead compared to BTRFS's own integrity guarantees. (TODO: Each user will have encrypted homedirs with fscrypt, but fscrypt doesn't support BTRFS yet).

### Updating the OS
As mentioned earlier, the operating system is deployed using immutable kernel and rootfs images that are cryptographically verified for authenticity (and integrity). These images bring the base OS, which contains only the [musl](https://musl.libc.org/about.html) libc, [hardened_malloc](https://github.com/GrapheneOS/hardened_malloc#security-properties), Flatpak, [Podman](https://github.com/containers/podman#overview-and-scope), [uutils-coreutils](https://github.com/uutils/coreutils), git, the [Helix](https://helix-editor.com/) text editor and the [Hyprland tilling window manager](https://hyprland.org/). Base OS image updates are built in the cloud via GitHub Actions, while the client side (heavily based on ChromiumOS' update_engine) downloads, verifies and A/B applies them. All of this happens weekly, automatically, and is cryptographically authenticated. The initial operating system instantiation contains an EFI partition, immutable root squashfs partitions A and B, and root-verity partitions A and B. There is also the home partition, which is the only persistent RW location on the system. It is also possible to factory reset the OS by formatting the home partition. Hardened mount options are applied for some mount points (for example, procfs on /proc has hide_pid=2, which prevents users from seeing each others processes). Also, /var is (volatile) tmpfs, so the system itself is stateless.

The operating system and the A/B updates will also act smartly enough to mark an update applied, say, on partition B, as failed if it does not boot correctly and reboot on partition A, where the previous working version of the system was.

### Network security
To address the lack of confidentiality, authenticity, and integrity of the old DNS protocol, [dnscrypt-proxy](https://github.com/DNSCrypt/dnscrypt-proxy) is used and /etc/resolv.conf points to it, providing strong system-wide in-transit encryption that ensures integrity, authenticity, and confidentiality for DNS queries and responses. As the old NTP protocol also does not provide authenticity, the newer [NTS](https://developers.cloudflare.com/time-services/nts/) is used to synchronize date and time with authenticity measures, because date and time correctness is essential for everyday cryptographic operations (like TLS handshakes).

Even though [dnscrypt-proxy](https://github.com/DNSCrypt/dnscrypt-proxy) introduces cryptographic confidentiality to DNS traffic, it is important to know that domain names can still be less confidential than expected because of SNI and OCSP leaks. If that's in the users' threat model, they should be using a VPN from a trusted, paid provider or Tor. The base OS image comes with [Wireguard](https://www.wireguard.com/) (for connecting to VPN servers) and [Arti](https://blog.torproject.org/arti_100_released/) (official Tor Project's Rust reimplementation) ready to use with sane defaults.

The operating system also has an extremely strict and stateful firewall configuration in order to always drop incoming traffic, and the kernel's TCP/IP stack is compiled with hardened configuration. Since disabling IPv4 is currently unfeasible because not everything on the Internet supports IPv6 yet, IPv6 is the one to be disabled directly in the kernel to reduce the attack surface of having an extra huge network protocol implementation.

### Exploit mitigations enforced by toolchain
The OS tends to prioritize Rust and memory safe languages, for example, the coreutils (ls, mv, dd, chmod, cat, among others) are memory safe (much less prone to memory corruption flaws), implemented in Rust by the [uutils](https://github.com/uutils/coreutils) project. Instead of nano and vim, text editing is powered by [Helix](https://helix-editor.com/), a text editor written in Rust. On the other hand, all C/C++ code within the base OS is compiled using modern exploit mitigations, mainly provided by the LLVM toolchain and its clang compiler, [which is more security-oriented than GNU's gcc](https://outflux.net/slides/2019/lpc/gcc-and-clang.pdf), so much so that projects like Android, Fuchsia, Chromium and ChromiumOS all take advantage of LLVM/clang security mitigations, even though they are more noticeable and prominent on arm64, but we're still on x86_64.

In the future, it is planned to migrate to the [COSMIC desktop environment](https://github.com/orgs/pop-os/repositories?q=cosmic&language=rust), which is going to be System76's complete desktop environment written in memory safe Rust.

### Display and audio servers
The OS uses [Wayland](https://wayland.freedesktop.org/) and [Pipewire](https://pipewire.org/), as they are secure, modern solutions and do not make sandbox escapes possible, instead of the both archaic and insecure Xorg and Pulseaudio. [Xorg (X11) always lacked GUI Isolation](https://theinvisiblethings.blogspot.com/2011/04/linux-security-circus-on-gui-isolation.html) and [PulseAudio features no isolation](https://www.freedesktop.org/wiki/Software/PulseAudio/Documentation/Developer/AccessControl/).

### Mandatory Access Control
System-wide SELinux policies will also act to further harden the OS with strict and fine-grained enforced policies in order to mitigate privilege escalation, container escapes, unauthorized access to certain system resources, etc.

### Chosen C library and malloc implementations
The chosen libc was [musl](https://musl.libc.org/about.html), as it is minimal, standardized and concise, bringing a substantially reduced attack surface. The libc's malloc implementation is replaced by Daniel Micay's [hardened_malloc](https://github.com/GrapheneOS/hardened_malloc#security-properties) from GrapheneOS, which mitigates various classes of memory corruption bugs and was, initially, heavily inspired by OpenBSD's malloc. Refer to the official [hardened_malloc](https://github.com/GrapheneOS/hardened_malloc#security-properties) documentation for its security properties.

### Kernel hardening
The OS kernel contains the [linux-hardened hardening patches](https://github.com/anthraxx/linux-hardened/commits), started by the GrapheneOS project a few years ago, but currenly maintained mainly by Levente Polyak from the Arch Linux project. The kernel is compiled with the minimum required modules and features, it also follows [Alexander Popov's kconfig-hardened-check](https://github.com/a13xp0p0v/kconfig-hardened-check) for baseline config recommendations from [KSPP](https://kernsec.org/wiki/index.php/Kernel_Self_Protection_Project/Recommended_Settings), grsec, [CLIP OS](https://docs.clip-os.org/clipos/kernel.html#configuration), kernel's defconfig, and [advice from kernel maintainers on Linux kernel secure build configurations](https://github.com/a13xp0p0v/kconfig-hardened-check/issues?q=label%3Akernel_maintainer_feedback). The kernel is also compiled with modern exploit mitigations such as [clang's CFI](https://cateee.net/lkddb/web-lkddb/CFI_CLANG.html).

Before the kernel, there is the bootloader, which is systemd-boot, a powerful UEFI-compatible bootloader. After the kernel, there is PID 1, which is the [runit system init](https://docs.voidlinux.org/config/services/index.html#services-and-daemons---runit), because it is minimal and has a smaller attack surface compared to systemd.

__Some__ details on kernel hardening are listed below, but these are not everything and you can even skip reading the list if you wish so:
* The Linux kernel lockdown LSM in its confidentiality mode protects the running kernel from userspace modifications, privilege escalation and risky syscalls. 
* To protect memory against DMA attacks and isolate memory regions between connected devices and I/O, the kernel enforces IOMMU (depends on Intel/AMD hardware support and its implementation being secure). Additionally, Thunderbolt and Firewire kernel modules are disabled because these usually allow DMA.
* Entropy and randomness are much higher in order to improve cryptographic operations and make the memory layout as unpredictable as possible.
* [Since ptrace allows programs to hook and inspect each others, ptrace is restricted by Yama in the kernel itself to keep sandboxes more secure and better overall process isolation.](https://www.kernel.org/doc/html/latest/admin-guide/LSM/Yama.html)
* kexec is disabled because it allows another kernel to load in runtime and could be exploited to obtain privileges.
* [Kernel pointer leaks relying on /proc and other interfaces are prevented thanks to a more restrict kptr_restrict flag](https://kernsec.org/wiki/index.php/Bug_Classes/Kernel_pointer_leak).
* eBPF now features JIT hardening (net.core.bpf_jit_harden) and lower attack surface as it is not exposed to unprivileged entities (kernel.unprivileged_bpf_disabled).
* Kernel pages' allocations are harder to predict and page table isolation (PTI) is enabled.
* The kernel does not load out-of-tree modules unless they are signed.
    * Therefore, until NVIDIA's own good open source drivers are incorporated into the upstream kernel (if they ever will be), it's good to avoid NVIDIA GPUs, as signing DKMS modules sucks compared to just using Intel or AMD GPUs and their open source drivers already upstreamed into the Linux kernel.
* Mitigations against speculative execution flaws are all enabled.
* Serious non-fatal kernel errors ("oopsies") sometimes are triggered by kernel-level exploitation and are therefore configured to cause kernel panics.
* vsyscalls are disabled as they are commonly used in return-oriented programming attacks and newer kernel versions have more secure alternatives (vDSO).
* The kernel stack offsets are randomized to harden against exploits that rely on a predictable memory layout. 
* Kernel SLABs are unable to merge in order to harden against heap exploitation.
* Kernel sensitive information doesn't appear in dmesg, boot, etc.
* [The userfaultfd() syscall is restricted because it can be misused to make it easier to exploit existing use-after-free bugs.](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=cefdca0a86be517bc390fc4541e3674b8e7803b0)
* To protect against rogue USB devices and physical exploitation of vulnerabilities using the USB interface, the kernel disables the entire USB subsystem after boot, which means that USB devices cannot be connected after OS boot, using userspace-level USBGuard policies would be less inconvenient (but also less secure) than having the kernel disable the entire USB subsystem after boot. In the future, it is planned to allow the user to enter their password into a utility to enable the USB subsystem for as long as they want, so they can plug in the devices they want in the meantime.

**Note that the above list is just a summary of highlights. The linux-hardened patches and kconfig sourced from [kconfig-hardened-check](https://github.com/a13xp0p0v/kconfig-hardened-check) (KSPP, CLIP OS, grsec, etc) will bring the best possible configuration for a hardened kernel, in addition to the reduced attack surface of a minimal kernel and [clang's CFI](https://cateee.net/lkddb/web-lkddb/CFI_CLANG.html) mitigation.**
